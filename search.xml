<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高性能MySQL笔记1 - 架构]]></title>
    <url>%2F2020%2F08%2F16%2Fmysql-note1%2F</url>
    <content type="text"><![CDATA[并发控制MySQL结构图 读写锁也叫做共享锁（shared lock）和排他锁（exclusive lock） 概念 读锁是共享的，相互不阻塞，多个用户可以在同一时间读区同一个资源，相互不干扰 写锁是排他的，一个写锁会阻塞其他的写锁和读锁，只有这样，才能保证在给定的时间内，只有一个用户能执行写入，并防止其他用户读区正在写入的同一资源 锁粒度 Note 提高系统并发性的方式是让锁对象更具有选择性，尽量只锁定需要修改的部分数据而不是所有的资源 锁的管理也需要资源开销，因此系统的性能和锁管理也有关系 锁策略就是在锁的开销和数据的安全性之间寻求平衡，每种MySQL存储引擎都可以实现自己的锁策略和锁粒度 表锁（table lock） Note 表锁是MySQL最基本的锁策略，开销最小，锁定整张表 写锁比读锁拥有更高的优先级，写锁可以插入到锁队列的前面，反之读锁不能插入到锁队列的前 MySQL服务器会为特定的操作使用有效的表锁，例如ALTER TABLE会使用表锁而忽略存储引擎的锁机制 行级锁（row lock） Note 行级锁可以最大程度的支持并发，同时也带来最大的锁开销 行级锁只有在存储引擎层实现，InnoDB和XtraDB均实现了行锁 事务定义： 一组原子性的SQL查询，或者说是一个独立的工作单元；（如果数据库引擎可以成功的应对该次查询的全部语句，则执行该组查询，否则所有的语句都不会执行） ACIDNote： 原子性(atomicity)：一个事物必须被视为一个不可分割的最小工作单元，要么所有操作全部提交成功，要么全部失败回滚 一致性(consistancy)：数据库总是从一个一致性的状态转换到另一个一致性的状态 隔离性(isolation)：通常来说，一个事务所做的修改在最终提交前，对其他事务不可见 持久性(durability)：一旦事务提交，则其所做的修改就会永远的保存到数据库中 隔离级别Note: SQL在标准中定义了四种隔离界别，每种级别规定了一个事物所做的修改，哪些是事务内和事务间可见的，哪些是不可见的。 较低的隔离界别通常可以执行更高的并发，系统的开销也更低 概念： READ UNCOMMITTED（未提交读）: 事务中的修改即使没有提交，对其他事务也是可见的，事务可以读取未提交的数据，称为脏读(dirty read) READ COMMITTED（提交读）：大多数数据库的默认隔离级别（MySQL不是）。事务开始前只能看见已经提交事务所做的修改，也就是说一个事务从开始直到提交之前，所做的修改都对其他事务不可见，也叫做不可重复读（nonrepeatable read），两次执行同样的查询，可能得到不一样的结果 REPEATABLE READ（可重复读）：解决了脏读的问题，保证事务内两次同样的查询得到相同的结果，但没有解决幻读（plantom read）的问题（某个事务在读取某个范围内的记录时，另一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围内的记录时，会产生幻行（plantom row））,InnoDB和XtraDB通过多版本控制（MVVC）解决幻读问题 SERIALIZABLE（可串行化）：最高的隔离级别，强制事务串行执行 死锁Note: 死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源时，导致的恶性循环的现象。多个事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时，也会产生死锁。 数据库实现了各种死锁检测以及死锁超时机制。越复杂的系统，越能检测到死锁的循环依赖，并立即返回一个错误。InnoDB目前处理死锁的方式是，将持有最少行级排他锁的事务进行回滚。 锁的行为和顺序是和存储引擎相关的，死锁产生有双重原因：有的是因为真正的数据冲突，有的则是因为存储引擎的实现方式导致的 死锁发生后，只有部分或者完全回滚其中一个事务，才能打破死锁，无法避免。 事务日志Note: 事务日志可以提高事务的效率，每次修改表的时候只需要修改其内存拷贝，然后吧修改行为记录到持久化在硬盘中的事务日志，而不用每次都把数据持久化到硬盘； 事务日志采用追加的方式，顺序写磁盘，效率高很多（普通硬盘） 内存中被修改后的数据可以在后台慢慢持久化到硬盘，事务日志被称为预写式日志（write-ahead logging），修改数据需要写两次硬盘 如果数据的修改已经持久化到事务日志，但数据本身没有写回磁盘，系统崩溃之后，存储引擎可以在重启的时候根据日志恢复数据 MySQL中的事务Note: MySQL提供了两种事务型的引擎：InnoDB和NDB Clusetr MySQL默认采用自动提交（Autocommit） 模式，即如果不是显示的开启一个事务，则每个查询都被当作一个事务提交。 尽量在事务中不要混合多种存储引擎（一次事务中出现事务型和非事务型的表），不然rollback就可能会发生问题导致最终的结果无法确定 InnoDB采用的两阶段锁定协议（two-phase locking protocol）。在事务的执行过程中随时可以执行锁定，只有在COMMIT或者ROLLBACK的时候会释放锁，所有锁在同一时刻释放（隐式锁） InnoDB也支持通过特定的语句来显式锁定select ... lock in share modeselect ... for update 多版本并发控制（MVCC）基本概念Note: MVVC是行级锁的变种，在很多情况下避免了加锁操作，开销更低，大多数都实现了非阻塞的读操作，写操作也只是锁定必要的行。 MVVC的实现是通过保存数据在某个时间点的快照来实现的，不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始时间的不同，每个事务对同一张表，同一个时刻看到的数据可能是不一样的。 不同存储引擎的MVVC实现有所不同，典型的有乐观并发控制和悲观并发控制。 MVVC只会在REPEATABLE READ和READ COMMITED两个隔离级别下生效，因为READ UNCOMMIED总会读取最新的数据行，而SERIALIZABLE则会对所有读取的行加锁 InnoDB的MVVC工作原理Note: InnoDB的MVVC是通过在每行记录后面加两个隐藏的列来实现的，一个烈保存了行的创建时间，一个列保存了行的删除时间，时间指的是系统版本号(system version number, 后面简写svn) 每开始一个新事务，svn会递增 在REPEATABLE READ隔离级别下的MVVC工作原理：SELECT: InnoDB会根据两个条件检查行： InnoDB只会查找svn小于等于当前事务版本的数据行 行的删除版本要么未定义要么大于当前事务版本号 INSERT: 为新插入的数据保存当前版本号为行版本号 DELETE: 为删除的每一行保存当前版本号为删除标识 INSERT: 插入一条新纪录，保存当前版本号为行版本号，同时保存当前版本号到原行作为删除标识]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[libtorch 的配置以及简单使用]]></title>
    <url>%2F2018%2F12%2F23%2Flibtorch-test%2F</url>
    <content type="text"><![CDATA[准备环境因为我的C++开发环境一直都是Windows下的Clion搭配WSL(Windows sub linux)，安装第三方库的时候比较方便（VS下的编译环境太复杂了，还各种问题）。这次要用到的库是libtorch，这个在Pytorch官网下载下来放到随便一个目录下解压即可，另外一个是OpenCV,我是用的OpenCV-3.4.4的版本，首先去官网下载到源码然后按照install tutorial（需要大概挺长时间的)。注： 所有的代码均来自于iamhankai,我只是稍微做了修改（原代码我跑不起来，可能是Libtorch有更新导致的），添加了一些注释。如果使用的不是Clion的话，可以参考iamhankai的Github给出的命令行的编译和执行过程。 配置C++项目环境使用Clion的话直接新建一个Project即可，编辑CMakeLists.txt文件，添加相应的库配置文件如下：12345678910111213cmake_minimum_required(VERSION 3.10)project(CppProject)set(CMAKE_CXX_STANDARD 11)set(Torch_DIR ~/libtorch/share/cmake/Torch) #根据自己保存的路径输入set(OpenCV_DIR ~/opencv-3.4.4/build) #编译OpenCV的时候创建的build文件夹find_package(Torch REQUIRED) #查找库find_package(OpenCV REQUIRED)add_executable(CppProject main.cpp)target_link_libraries(CppProject $&#123;OpenCV_LIBS&#125; $&#123;TORCH_LIBRARIES&#125; ) #添加链接文件 使用Python保存模型到本地新建一个Python的脚本文件，这个文件主要是下载一个预训练模型然后使用JIT保存到本地。本且使用本地的一张图片来进行预测。代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import torchimport torchvisionfrom torchvision import transformsfrom PIL import Imagefrom time import timeimport numpy as np# 加载预训练模型model = torchvision.models.resnet18(pretrained=True)model.eval() # 评估模式# 生成一个随机Tensor,Pytorch是基于动态图的框架，需要必须先计算一次前向传播example = torch.rand(1, 3, 224, 224)# 使用torch.jit.trace生成一个torch.jit.ScriptModuletraced_script_module = torch.jit.trace(model, example)traced_script_module.save("model.pt") # 保存模型# 计算一次前向传播所需要的时间batch = torch.rand(64, 3, 224, 224)start = time()output = traced_script_module(batch)stop = time()print(str(stop - start) + "s")# 读取本地的照片image = Image.open('dog.png').convert('RGB')default_transform = transforms.Compose([ transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])image = default_transform(image)# 前向传播output = traced_script_module(image.unsqueeze(0))# print(output[0, :10])# 预测打印Top-5labels = np.loadtxt('synset_words.txt', dtype=str, delimiter='\n')data_out = output[0].data.numpy()sorted_idxs = np.argsort(-data_out)for i, idx in enumerate(sorted_idxs[:5]): print(f"label: &#123;labels[idx]&#125;, score: &#123;data_out[idx]&#125;")运行结果如下： C++加载模型使用C++进行模型的加载，然后使用OpenCV来读取一张图片并执行预测，代码的过程和Python脚本差不多。下面是main.cpp代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;torch/script.h&gt;#include &lt;torch/torch.h&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/core.hpp&gt;#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;string&gt;#include &lt;vector&gt;/* main */int main(int argc, const char *argv[]) &#123; //接受三个运行参数 //1. 模型 //2. 要预测的图片 //3. label的文本 if (argc &lt; 4) &#123; std::cerr &lt;&lt; "usage: CppProject &lt;path-to-exported-script-module&gt; " &lt;&lt; "&lt;path-to-image&gt; &lt;path-to-category-text&gt;\n"; return -1; &#125; //加载模型 std::shared_ptr&lt;torch::jit::script::Module&gt; module = torch::jit::load(argv[1]); assert(module != nullptr); std::cout &lt;&lt; "load model ok\n"; //生成一个随机输入 std::vector&lt;torch::jit::IValue&gt; inputs; inputs.emplace_back(torch::rand(&#123;64, 3, 224, 224&#125;)); // 计算网络一次前向传播的需要时间 auto t = (double) cv::getTickCount(); module-&gt;forward(inputs).toTensor(); t = (double) cv::getTickCount() - t; printf("execution time = %gs\n", t / cv::getTickFrequency()); inputs.pop_back(); // 记载一张图片并且进行归一化 cv::Mat image; image = cv::imread(argv[2], 1); cv::cvtColor(image, image, CV_BGR2RGB); //转化为RGB三通道 cv::Mat img_float; image.convertTo(img_float, CV_32F, 1.0 / 255); //首先归一化到[0,1]区间 cv::resize(img_float, img_float, cv::Size(224, 224)); //resize to 224，预训练的模型输入是batchsize x3 x 224 x 224 //std::cout &lt;&lt; img_float.at&lt;cv::Vec3f&gt;(56,34)[1] &lt;&lt; std::endl; auto img_tensor = torch::CPU(torch::kFloat32).tensorFromBlob(img_float.data, &#123;1, 224, 224, 3&#125;); //将cv::Mat转成tensor img_tensor = img_tensor.permute(&#123;0, 3, 1, 2&#125;); //翻转让通道是第二个维度 //均值归一化 img_tensor[0][0] = img_tensor[0][0].sub_(0.485).div_(0.229); img_tensor[0][1] = img_tensor[0][1].sub_(0.456).div_(0.224); img_tensor[0][2] = img_tensor[0][2].sub_(0.406).div_(0.225); auto img_var = torch::autograd::make_variable(img_tensor, false); inputs.emplace_back(img_var); //对输入的图片进行前向传播计算 torch::Tensor out_tensor = module-&gt;forward(inputs).toTensor(); //std::cout &lt;&lt; out_tensor.slice(/*dim=*/1, /*start=*/0, /*end=*/10) &lt;&lt; '\n'; // 加载label的文件 std::string label_file = argv[3]; std::ifstream rf(label_file.c_str()); CHECK(rf) &lt;&lt; "Unable to open labels file " &lt;&lt; label_file; std::string line; std::vector&lt;std::string&gt; labels; while (std::getline(rf, line)) labels.push_back(line); // 打印score是Top-5的预测label和score std::tuple&lt;torch::Tensor, torch::Tensor&gt; result = out_tensor.sort(-1, true); torch::Tensor top_scores = std::get&lt;0&gt;(result)[0]; torch::Tensor top_idxs = std::get&lt;1&gt;(result)[0].toType(torch::kInt32); auto top_scores_a = top_scores.accessor&lt;float, 1&gt;(); //1是dim auto top_idxs_a = top_idxs.accessor&lt;int, 1&gt;(); for (int i = 0; i &lt; 5; ++i) &#123; std::cout &lt;&lt; "score: " &lt;&lt; top_scores_a[i]; std::cout &lt;&lt; " label: " &lt;&lt; labels[top_idxs_a[i]] &lt;&lt; std::endl; &#125; return 0;&#125;运行结果如下： 总结通过Python代码和C++的运行结果可以看出来，C++的执行还是更快一点的。而且Pytorch的C++写起来也还是听方便的，很多API和Python都差不多。完整的项目可以在我的Github里面TorchDemo找到。]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>Libtorch</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PASCAL VOC数据集]]></title>
    <url>%2F2018%2F12%2F19%2FPASCAL-dataset%2F</url>
    <content type="text"><![CDATA[PASCAL VOC数据集是什么？最近在看Yolo1的论文，因为论文中使用到了PASCAL VOC数据集，这个之前没接触过，到官网下载后完全不知道怎么用，看了一些相关的介绍后，才明白该数据集的组成。这里PASCAL是Pattern Analysis, Statistical Modelling and Computational Learning的简写，VOC是Visual Object Classes的简写。 数据集的组成将数据集下载解压之后的样子如下： 在检测和识别问题中，关注的是Annotations, ImageSets,以及JPEGImages三个文件夹。在JPEGImages文件中就是数据集中的所有图片了，总共有17125张。这个文件夹包含了所有的训练和测试数据，命名的格式为：年份_编号.jpg。 重点关注的文件夹是Annotations,从命名就可以知道里面是标注的信息。这个文件夹下的文件命名和JPEGImages文件夹下面是对应的，只是后缀名不同。PASCAL数据集使用了xml格式的标签文件来保存数据。值得注意的是，一张图片可能存在多个物体，所以标注中可能会出现多个bounding box的信息。对2007_000027.jpg文件来说，它的标注信息如下： 在目标检测中我们更加关注的是红色框中的内容，我们要从中提取到类别和bounding box的相关信息，对应于xml中的name和bndbox中的数据，其中bounding box给出的标注数据是左上角和右下角的绝对坐标。接下来使用Python的xml解析库来提取其中的内容。1234567891011121314import xml.etree.ElementTree as ETdef parse_pascal(xml_file_path): tree = ET.parse(xml_file_path) root = tree.getroot() info = [] for c in root.findall('object'): label = c.find('name').text x1 = int(float(c.find('./bndbox/xmin').text)) y1 = int(float(c.find('./bndbox/ymin').text)) x2 = int(float(c.find('./bndbox/xmax').text)) y2 = int(float(c.find('./bndbox/ymax').text)) info.append((label, x1, y1, x2, y2)) return info 代码很简单，稍微去看一下xml库的tutorial就可以写出来了，有一点比较坑的是有几个标注文件的bounding box出现了小数，说实话我就不是很懂是什么意思了，所以我这里就直接将它强制转化为了int。 最后是ImageSets文件夹，这个文件夹下面又包含了四个文件夹，其中Action下存放的是人的动作的数据，Layout下存放的是人体部位的数据，Main下存访的是图像物体识别的数据，总共包含20类，Segmentation下存放的是用于图像分割的数据。这里主要说说Main目录，它下面包含了所有分类的train, trainval, val的数据，每个txt文件里面都有两列，一列是文件的名称，一列是表示正负样本（目标检测中还用不到）。其实，这个文件夹最重要的作用就是用来划分数据集。 _train中存放的是训练使用的数据，每一个class的train数据都有5717个。 _val中存放的是验证结果使用的数据，每一个class的val数据都有5823个。 _trainval将上面两个进行了合并，每一个class有11540个。 最后放一张带有bounding box的图片吧 数据集划分的实现数据集的划分主要就是根据ImageSets文件夹下面的Main文件下的_train和_val文件，对20个类进行遍历，然后将对应的图片和标注数据放在某个文件夹下面。这个过程还是很简单的，下面是具体的实现代码：12345678910111213141516171819202122232425262728293031323334import osimport shutildef split(file_path, images_path, save_path): """ file path: path to ImageSets/Main/ images_path : path to JEPGImages save_path: path to save """ classes = os.listdir(file_path) ## 得到需要的train和val的数据 train = [] val = [] for f in classes: if f.endswith("_train.txt"): train.append(file_path + '/' + f) elif f.endswith("_val.txt"): val.append(file_path + '/' + f) for c in train: with open(c, 'r') as f: for line in f: img_name = line.split(" ")[0] + '.jpg' src_path = images_path + '/'+ img_name dest_path = save_path + '/train/' + img_name shutil.copyfile(src_path, dest_path) for c in val: with open(c, 'r') as f: for line in f: img_name = line.split(" ")[0] + '.jpg' src_path = images_path + '/'+ img_name dest_path = save_path + '/test/' + img_name shutil.copyfile(src_path, dest_path)参数为ImageSets，JPEGImages的路径以及保存的路径(该目录下应该有train和test文件夹)，调用该函数等一段时间即可完成数据集的划分。 参考文献PASCAL VOC数据集分析PASCAL VOC数据集的标注格式]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>VOC</tag>
        <tag>Python</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello world]]></title>
    <url>%2F2018%2F12%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>工具</category>
      </categories>
  </entry>
</search>
