<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[libtorch 的配置以及简单使用]]></title>
    <url>%2F2018%2F12%2F23%2Flibtorch-test%2F</url>
    <content type="text"><![CDATA[准备环境因为我的C++开发环境一直都是Windows下的Clion搭配WSL(Windows sub linux)，安装第三方库的时候比较方便（VS下的编译环境太复杂了，还各种问题）。这次要用到的库是libtorch，这个在Pytorch官网下载下来放到随便一个目录下解压即可，另外一个是OpenCV,我是用的OpenCV-3.4.4的版本，首先去官网下载到源码然后按照install tutorial（需要大概挺长时间的)。注： 所有的代码均来自于iamhankai,我只是稍微做了修改（原代码我跑不起来，可能是Libtorch有更新导致的），添加了一些注释。如果使用的不是Clion的话，可以参考iamhankai的Github给出的命令行的编译和执行过程。 配置C++项目环境使用Clion的话直接新建一个Project即可，编辑CMakeLists.txt文件，添加相应的库配置文件如下：12345678910111213cmake_minimum_required(VERSION 3.10)project(CppProject)set(CMAKE_CXX_STANDARD 11)set(Torch_DIR ~/libtorch/share/cmake/Torch) #根据自己保存的路径输入set(OpenCV_DIR ~/opencv-3.4.4/build) #编译OpenCV的时候创建的build文件夹find_package(Torch REQUIRED) #查找库find_package(OpenCV REQUIRED)add_executable(CppProject main.cpp)target_link_libraries(CppProject $&#123;OpenCV_LIBS&#125; $&#123;TORCH_LIBRARIES&#125; ) #添加链接文件 使用Python保存模型到本地新建一个Python的脚本文件，这个文件主要是下载一个预训练模型然后使用JIT保存到本地。本且使用本地的一张图片来进行预测。代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import torchimport torchvisionfrom torchvision import transformsfrom PIL import Imagefrom time import timeimport numpy as np# 加载预训练模型model = torchvision.models.resnet18(pretrained=True)model.eval() # 评估模式# 生成一个随机Tensor,Pytorch是基于动态图的框架，需要必须先计算一次前向传播example = torch.rand(1, 3, 224, 224)# 使用torch.jit.trace生成一个torch.jit.ScriptModuletraced_script_module = torch.jit.trace(model, example)traced_script_module.save("model.pt") # 保存模型# 计算一次前向传播所需要的时间batch = torch.rand(64, 3, 224, 224)start = time()output = traced_script_module(batch)stop = time()print(str(stop - start) + "s")# 读取本地的照片image = Image.open('dog.png').convert('RGB')default_transform = transforms.Compose([ transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])image = default_transform(image)# 前向传播output = traced_script_module(image.unsqueeze(0))# print(output[0, :10])# 预测打印Top-5labels = np.loadtxt('synset_words.txt', dtype=str, delimiter='\n')data_out = output[0].data.numpy()sorted_idxs = np.argsort(-data_out)for i, idx in enumerate(sorted_idxs[:5]): print(f"label: &#123;labels[idx]&#125;, score: &#123;data_out[idx]&#125;")运行结果如下： C++加载模型使用C++进行模型的加载，然后使用OpenCV来读取一张图片并执行预测，代码的过程和Python脚本差不多。下面是main.cpp代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;torch/script.h&gt;#include &lt;torch/torch.h&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/core.hpp&gt;#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;string&gt;#include &lt;vector&gt;/* main */int main(int argc, const char *argv[]) &#123; //接受三个运行参数 //1. 模型 //2. 要预测的图片 //3. label的文本 if (argc &lt; 4) &#123; std::cerr &lt;&lt; "usage: CppProject &lt;path-to-exported-script-module&gt; " &lt;&lt; "&lt;path-to-image&gt; &lt;path-to-category-text&gt;\n"; return -1; &#125; //加载模型 std::shared_ptr&lt;torch::jit::script::Module&gt; module = torch::jit::load(argv[1]); assert(module != nullptr); std::cout &lt;&lt; "load model ok\n"; //生成一个随机输入 std::vector&lt;torch::jit::IValue&gt; inputs; inputs.emplace_back(torch::rand(&#123;64, 3, 224, 224&#125;)); // 计算网络一次前向传播的需要时间 auto t = (double) cv::getTickCount(); module-&gt;forward(inputs).toTensor(); t = (double) cv::getTickCount() - t; printf("execution time = %gs\n", t / cv::getTickFrequency()); inputs.pop_back(); // 记载一张图片并且进行归一化 cv::Mat image; image = cv::imread(argv[2], 1); cv::cvtColor(image, image, CV_BGR2RGB); //转化为RGB三通道 cv::Mat img_float; image.convertTo(img_float, CV_32F, 1.0 / 255); //首先归一化到[0,1]区间 cv::resize(img_float, img_float, cv::Size(224, 224)); //resize to 224，预训练的模型输入是batchsize x3 x 224 x 224 //std::cout &lt;&lt; img_float.at&lt;cv::Vec3f&gt;(56,34)[1] &lt;&lt; std::endl; auto img_tensor = torch::CPU(torch::kFloat32).tensorFromBlob(img_float.data, &#123;1, 224, 224, 3&#125;); //将cv::Mat转成tensor img_tensor = img_tensor.permute(&#123;0, 3, 1, 2&#125;); //翻转让通道是第二个维度 //均值归一化 img_tensor[0][0] = img_tensor[0][0].sub_(0.485).div_(0.229); img_tensor[0][1] = img_tensor[0][1].sub_(0.456).div_(0.224); img_tensor[0][2] = img_tensor[0][2].sub_(0.406).div_(0.225); auto img_var = torch::autograd::make_variable(img_tensor, false); inputs.emplace_back(img_var); //对输入的图片进行前向传播计算 torch::Tensor out_tensor = module-&gt;forward(inputs).toTensor(); //std::cout &lt;&lt; out_tensor.slice(/*dim=*/1, /*start=*/0, /*end=*/10) &lt;&lt; '\n'; // 加载label的文件 std::string label_file = argv[3]; std::ifstream rf(label_file.c_str()); CHECK(rf) &lt;&lt; "Unable to open labels file " &lt;&lt; label_file; std::string line; std::vector&lt;std::string&gt; labels; while (std::getline(rf, line)) labels.push_back(line); // 打印score是Top-5的预测label和score std::tuple&lt;torch::Tensor, torch::Tensor&gt; result = out_tensor.sort(-1, true); torch::Tensor top_scores = std::get&lt;0&gt;(result)[0]; torch::Tensor top_idxs = std::get&lt;1&gt;(result)[0].toType(torch::kInt32); auto top_scores_a = top_scores.accessor&lt;float, 1&gt;(); //1是dim auto top_idxs_a = top_idxs.accessor&lt;int, 1&gt;(); for (int i = 0; i &lt; 5; ++i) &#123; std::cout &lt;&lt; "score: " &lt;&lt; top_scores_a[i]; std::cout &lt;&lt; " label: " &lt;&lt; labels[top_idxs_a[i]] &lt;&lt; std::endl; &#125; return 0;&#125;运行结果如下： 总结通过Python代码和C++的运行结果可以看出来，C++的执行还是更快一点的。而且Pytorch的C++写起来也还是听方便的，很多API和Python都差不多。]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>Libtorch</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PASCAL VOC数据集]]></title>
    <url>%2F2018%2F12%2F19%2FPASCAL-dataset%2F</url>
    <content type="text"><![CDATA[PASCAL VOC数据集是什么？最近在看Yolo1的论文，因为论文中使用到了PASCAL VOC数据集，这个之前没接触过，到官网下载后完全不知道怎么用，看了一些相关的介绍后，才明白该数据集的组成。这里PASCAL是Pattern Analysis, Statistical Modelling and Computational Learning的简写，VOC是Visual Object Classes的简写。 数据集的组成将数据集下载解压之后的样子如下： 在检测和识别问题中，关注的是Annotations, ImageSets,以及JPEGImages三个文件夹。在JPEGImages文件中就是数据集中的所有图片了，总共有17125张。这个文件夹包含了所有的训练和测试数据，命名的格式为：年份_编号.jpg。 重点关注的文件夹是Annotations,从命名就可以知道里面是标注的信息。这个文件夹下的文件命名和JPEGImages文件夹下面是对应的，只是后缀名不同。PASCAL数据集使用了xml格式的标签文件来保存数据。值得注意的是，一张图片可能存在多个物体，所以标注中可能会出现多个bounding box的信息。对2007_000027.jpg文件来说，它的标注信息如下： 在目标检测中我们更加关注的是红色框中的内容，我们要从中提取到类别和bounding box的相关信息，对应于xml中的name和bndbox中的数据，其中bounding box给出的标注数据是左上角和右下角的绝对坐标。接下来使用Python的xml解析库来提取其中的内容。1234567891011121314import xml.etree.ElementTree as ETdef parse_pascal(xml_file_path): tree = ET.parse(xml_file_path) root = tree.getroot() info = [] for c in root.findall('object'): label = c.find('name').text x1 = int(float(c.find('./bndbox/xmin').text)) y1 = int(float(c.find('./bndbox/ymin').text)) x2 = int(float(c.find('./bndbox/xmax').text)) y2 = int(float(c.find('./bndbox/ymax').text)) info.append((label, x1, y1, x2, y2)) return info 代码很简单，稍微去看一下xml库的tutorial就可以写出来了，有一点比较坑的是有几个标注文件的bounding box出现了小数，说实话我就不是很懂是什么意思了，所以我这里就直接将它强制转化为了int。 最后是ImageSets文件夹，这个文件夹下面又包含了四个文件夹，其中Action下存放的是人的动作的数据，Layout下存放的是人体部位的数据，Main下存访的是图像物体识别的数据，总共包含20类，Segmentation下存放的是用于图像分割的数据。这里主要说说Main目录，它下面包含了所有分类的train, trainval, val的数据，每个txt文件里面都有两列，一列是文件的名称，一列是表示正负样本（目标检测中还用不到）。其实，这个文件夹最重要的作用就是用来划分数据集。 _train中存放的是训练使用的数据，每一个class的train数据都有5717个。 _val中存放的是验证结果使用的数据，每一个class的val数据都有5823个。 _trainval将上面两个进行了合并，每一个class有11540个。 最后放一张带有bounding box的图片吧 数据集划分的实现数据集的划分主要就是根据ImageSets文件夹下面的Main文件下的_train和_val文件，对20个类进行遍历，然后将对应的图片和标注数据放在某个文件夹下面。这个过程还是很简单的，下面是具体的实现代码：12345678910111213141516171819202122232425262728293031323334import osimport shutildef split(file_path, images_path, save_path): """ file path: path to ImageSets/Main/ images_path : path to JEPGImages save_path: path to save """ classes = os.listdir(file_path) ## 得到需要的train和val的数据 train = [] val = [] for f in classes: if f.endswith("_train.txt"): train.append(file_path + '/' + f) elif f.endswith("_val.txt"): val.append(file_path + '/' + f) for c in train: with open(c, 'r') as f: for line in f: img_name = line.split(" ")[0] + '.jpg' src_path = images_path + '/'+ img_name dest_path = save_path + '/train/' + img_name shutil.copyfile(src_path, dest_path) for c in val: with open(c, 'r') as f: for line in f: img_name = line.split(" ")[0] + '.jpg' src_path = images_path + '/'+ img_name dest_path = save_path + '/test/' + img_name shutil.copyfile(src_path, dest_path)参数为ImageSets，JPEGImages的路径以及保存的路径(该目录下应该有train和test文件夹)，调用该函数等一段时间即可完成数据集的划分。 参考文献PASCAL VOC数据集分析PASCAL VOC数据集的标注格式]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>VOC</tag>
        <tag>Python</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello world]]></title>
    <url>%2F2018%2F12%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>工具</category>
      </categories>
  </entry>
</search>
